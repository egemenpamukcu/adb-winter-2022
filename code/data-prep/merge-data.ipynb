{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Data\n",
    "Code in this notebook collects data from the \"intermediate data\" folder and merges it, producing a merged_data.csv and variables.csv. You will need to change path variables to be able to run it on your own machine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pycountry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check required columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World Bank Climate Knowledge Portal.csv iso: True\n",
      "World Bank Climate Knowledge Portal.csv year: True\n",
      "World Bank Climate Knowledge Portal.csv data_source: True\n",
      "World Bank Climate Knowledge Portal.csv country_name: True\n",
      "UN_HDI_EnvPillar_clean_updated.csv iso: True\n",
      "UN_HDI_EnvPillar_clean_updated.csv year: True\n",
      "UN_HDI_EnvPillar_clean_updated.csv data_source: True\n",
      "UN_HDI_EnvPillar_clean_updated.csv country_name: True\n",
      "ADB_CPA_clean_updated.csv iso: True\n",
      "ADB_CPA_clean_updated.csv year: True\n",
      "ADB_CPA_clean_updated.csv data_source: True\n",
      "ADB_CPA_clean_updated.csv country_name: True\n",
      "IDMC_Conflict and Disaster Total.csv iso: True\n",
      "IDMC_Conflict and Disaster Total.csv year: True\n",
      "IDMC_Conflict and Disaster Total.csv data_source: True\n",
      "IDMC_Conflict and Disaster Total.csv country_name: True\n",
      "UNDESA_clean_updated.csv iso: True\n",
      "UNDESA_clean_updated.csv year: True\n",
      "UNDESA_clean_updated.csv data_source: True\n",
      "UNDESA_clean_updated.csv country_name: True\n",
      "epi.csv iso: True\n",
      "epi.csv year: True\n",
      "epi.csv data_source: True\n",
      "epi.csv country_name: True\n",
      "V-Dem.csv iso: True\n",
      "V-Dem.csv year: True\n",
      "V-Dem.csv data_source: True\n",
      "V-Dem.csv country_name: True\n",
      "wb_macro.csv iso: True\n",
      "wb_macro.csv year: True\n",
      "wb_macro.csv data_source: True\n",
      "wb_macro.csv country_name: True\n",
      "fsi_clean_updated .csv iso: True\n",
      "fsi_clean_updated .csv year: True\n",
      "fsi_clean_updated .csv data_source: True\n",
      "fsi_clean_updated .csv country_name: True\n",
      "wgi_clean_updated.csv iso: True\n",
      "wgi_clean_updated.csv year: True\n",
      "wgi_clean_updated.csv data_source: True\n",
      "wgi_clean_updated.csv country_name: True\n",
      "cri.csv iso: True\n",
      "cri.csv year: True\n",
      "cri.csv data_source: True\n",
      "cri.csv country_name: True\n",
      "CPIA.csv iso: True\n",
      "CPIA.csv year: True\n",
      "CPIA.csv data_source: True\n",
      "CPIA.csv country_name: True\n"
     ]
    }
   ],
   "source": [
    "ADB_MEMBERS_DIR = '../../data/final/adb-members.csv'\n",
    "GENERIC_COLS = ['iso', 'year', 'data_source', 'country_name']\n",
    "DATA_DIR = '../../data/inter'\n",
    "for csv in [x for x in os.listdir(DATA_DIR) if x.endswith('.csv')]:\n",
    "    csv_path = os.path.join(DATA_DIR, csv)\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "    except UnicodeDecodeError:\n",
    "        df = pd.read_csv(csv_path, engine='python')\n",
    "    for col in GENERIC_COLS:\n",
    "        print(csv, col + ':', col in df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_variables():\n",
    "    variables = {\n",
    "        'file_name': [],\n",
    "        'data_source': [],\n",
    "        'variable': [],\n",
    "        'min_year': [],\n",
    "        'max_year': [], \n",
    "    }\n",
    "    for csv in [x for x in os.listdir(DATA_DIR) if x.endswith('.csv')]:\n",
    "        csv_path = os.path.join(DATA_DIR, csv)\n",
    "        try: \n",
    "            df = pd.read_csv(csv_path)\n",
    "        except UnicodeDecodeError:\n",
    "            df = pd.read_csv(csv_path, engine='python')\n",
    "        for col in df.columns:\n",
    "            if col not in GENERIC_COLS:\n",
    "                variables['file_name'].append(csv)\n",
    "                variables['data_source'].append(df.at[0, 'data_source'])\n",
    "                variables['variable'].append(col)\n",
    "                variables['max_year'].append(df.dropna(axis=0, subset=[col]).year.max())\n",
    "                variables['min_year'].append(df.dropna(axis=0, subset=[col]).year.min())\n",
    "\n",
    "    var_df = pd.DataFrame(variables)\n",
    "    return var_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_country_name(iso):\n",
    "    try:    \n",
    "        return pycountry.countries.get(alpha_3=iso).name\n",
    "    except AttributeError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data():\n",
    "    \n",
    "    for i, csv in enumerate([x for x in os.listdir(DATA_DIR) if x.endswith('.csv')]):\n",
    "        csv_path = os.path.join(DATA_DIR, csv)\n",
    "        if i == 0:\n",
    "            try: \n",
    "                df = pd.read_csv(csv_path)\n",
    "            except UnicodeDecodeError:\n",
    "                df = pd.read_csv(csv_path, engine='python')\n",
    "\n",
    "            df = df.drop(['country_name', 'data_source'], axis=1)\n",
    "        else:\n",
    "            try: \n",
    "                merge_df = pd.read_csv(csv_path).drop(['country_name', 'data_source'], axis=1)\n",
    "            except UnicodeDecodeError:\n",
    "                merge_df = pd.read_csv(csv_path, engine='python').drop(['country_name', 'data_source'], axis=1)\n",
    "            df = df.merge(merge_df, how='outer', on=['iso', 'year'])\n",
    "    df.dropna(0, subset=['iso', 'year'], inplace=True, how='any')\n",
    "    country_names = df['iso'].apply(get_country_name)\n",
    "    df.insert(1, 'country_name', country_names)\n",
    "    adb = pd.read_csv(ADB_MEMBERS_DIR)\n",
    "    adb = adb[adb.membership_type=='Regional']\n",
    "    df = df[df['iso'].isin(adb.iso)]\n",
    "    # df = df[df['year'] >= 2010]\n",
    "    df['year'] = df['year'].astype(int)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = merge_data()\n",
    "variables = get_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../../data/final/merged_data.csv', index=False)\n",
    "variables.to_csv('../../data/final/variables.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a3d5db6a634964789429d20b83b64765f0032d35335aeeae34e128278d380194"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
